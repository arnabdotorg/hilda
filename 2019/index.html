<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<link rel="shortcut icon" href="img/favicon.ico"> 
	<link rel="stylesheet" href="css/vendor/fluidbox.min.css">
	<link rel="stylesheet" href="css/main.css">

	<title>HILDA 2019: Workshop on Human-In-the-Loop Data Analytics</title>
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
	<script>
	if (!window.jQuery) 
	{
	    document.write('<script src="js/vendor/jquery.1.11.min.js"><\/script>');
	}
	</script>


</head>
<body>


	<header>

		<div id="logo-container">
			<div id="logo"><a href="/">HILDA 2019</a></div>
			<div id="subtitle">Workshop on Human-In-the-Loop Data Analytics</div>
			<div>Co-located with <a href="http://sigmod2019.org">SIGMOD 2019</a> (5 July 2019, Amsterdam, Netherlands)</div>
            <div><br /><a href="https://twitter.com/hildaworkshop" class="twitter-follow-button" data-show-count="false" data-size="large">Follow @hildaworkshop</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script> <a href="https://twitter.com/intent/tweet?button_hashtag=hilda2019" class="twitter-hashtag-button" data-size="large" data-related="arnabdotorg">Tweet #hilda2019</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
	    
	    <br /><br />Past workshops: <a href="http://hilda.io/2016">HILDA 2016</a> | <a href="http://hilda.io/2017">HILDA 2017</a></strong> | <a href="http://hilda.io/2018">HILDA 2018</a>
	    
	    	</div>
		</div>
<!-- 		<nav>
			<ul>
				<li><a href="#">Link 1</a></li>
				<li><a href="#">Link 2</a></li>
				<li><a href="#">Link 3</a></li> 
				<li><a href="mailto:your@address.com" class="bordered">Contact</a></li>
			</ul>
		</nav> -->

	</header>


	<div id="content">

		<section class="row">
			<div class="col-full">
				<h2>Introduction</h2>
				<p>Any data management system needs to work together with people, whose needs determine the goals for the system, and who must provide the input and who need to work effectively with the output. Data management systems will work much better when they take account of the cognitive and physiological characteristics of the people involved. Recent technology trends (such as touch screens, motion detection, and voice recognition) are widening the possibilities for users to interact with systems, and many information-provision industries are shifting to personalized processing to better target their services to the users’ wishes. HILDA is a workshop that will allow researchers and practitioners to exchange ideas and results relating to how data management can be done with awareness of the people who form part of the processes. A sample of topics that is are in the spirit of this workshop includes, but is not limited to: novel query interfaces, interactive query refinement, data exploration and analysis, data visualization, human-assisted data integration and cleaning, perception-aware data processing, database systems designed for highly interactive use cases, empirical studies of database use, and crowd-powered data infrastructure.</p> 

				<p>HILDA intends to be a forum where people from varied communities engage with one another's ideas. We are keen to have submissions that present initial ideas and visions, just as much as reports on early results, or reflections on completed projects. The workshop will focus on discussion and interaction, rather than static presentations of what is in the paper.</p>
			</div>
		</section>
		
<section class="row">
			<div class="col-full">
				<h2>Submission</h2>

<p>Authors are invited to submit either of the following: (1) original, unpublished research papers that are not being considered for publication in any other forum.  These will be published in the HILDA proceedings, or (2) abstracts of previous work presented in other venues ideally outside the database community.</p> 

<p>Abstracts will be considered for discussion at the workshop only and not be included in the HILDA proceedings. Submissions of abstracts must be marked in the title as (Abstract). Research papers must follow the latest ACM Proceedings format (2017). Research papers submitted can be between four and six pages in length, excluding references. Abstracts should be maximally one page long. </p>

<p> Submissions will be handled through <a href="https://easychair.org/conferences/?conf=hilda2019">EasyChair</a>.</p>

		<section class="row">
			<div class="col">
				
				<h2>Keynote Speakers</h2>
				<p>
					<ul>
					<li>TBD</li>
					</ul>
				</p></br />

				<h2>Panelists (Pending)</h2>
        <p>We are excited to host a panel of researchers to discuss directions where communities can collaborate.</p>
				<p>
					<ul>
            <li>TBD</li>
            <!--<li><a href="http://arvindsatya.com/">Arvind Satyanarayan</a> (MIT)</li>-->
					</ul>
				</p></br />
	
				
				<h2>Proceedings</h2>
				<p>
					<ul>
					<li>All HILDA papers are available in the ACM DL for a one year period from the conference start date<!-- <a href="http://dl.acm.org/citation.cfm?id=3209900">here</a> -->.  </li>
				</p></br />
				
				<h2>Important Dates</h2>
				<p>
					<ul>
					<li>Workshop Date: July 5, 2019</li>
          <li>Submissions (Research Papers): March <b>16</b>, 2019, 11:59PM US PDT</li>
          <!-- <li>Submissions (Abstract-only): April 6, 2019, 11.59PM US EDT</li> -->
          <li>Notification of outcome: April 13, 2019 11:59PM US PDT (before SIGMOD early registration deadline)</li>
					<li>Camera-ready due: April 27, 2019 11:59PM US PDT <br/></li>
					</ul>			
				</p><br />
				<h2>Related Workshops</h2>
				<p>
					<ul>
					<li><a href="http://poloclub.gatech.edu/idea2019/">IDEA @ KDD 2018</a></li>
					<li><a href="http://www.interactive-analysis.org/">DSIA @ VIS 2018</a></li>
				</ul>			
				</p>								

			</div>

			<div class="col">	
			    <h2>Program Chairs</h2>		
			    <p>
					<ul>
            <li><a href="https://www.cs.umd.edu/~leilani">Leilani Battle</a> (Univeristy of Maryland, co-chair) </li>
            <li><a href="https://www.microsoft.com/en-us/research/people/surajitc/">Surajit Chaudhuri</a> (Microsoft Research, co-chair)</li>            
            <li><a href="http://arnab.org">Arnab Nandi</a> (The Ohio State University, co-chair)</li>            
					</ul>
				</p>
			    	
				<h2>Program Committee</h2>
				<p>
					<ul>
            <li>TBD</li>
<!-- <li>Aditya Parameswaran, University of Illinois</li>
<li>Adriane Chapman, University of Southampton</li>
<li>Anil Bahuman, Reliance Industries</li>
<li>Anushka Anand, Tableau Software</li>
<li>Arnab Nandi, The Ohio State University</li>
<li>Beth Trushkowsky, Harvey Mudd College</li>
<li>Brian Lim, NUS Singapore</li>
<li>Carl-Christian Kanne, Platfora</li>
<li>Carlos Scheidegger, University of Arizona</li>
<li>Chris Re, Stanford University</li>
<li>Dafna Shahaf, Hebrew University Jerusalem</li>
<li>Danyel Fisher, Microsoft Research</li>
<li>Dana Groff, MongoDB</li>
<li>Dominik Moritz, University of Washington</li>
<li>Enrico Bertini, New York University</li>
<li>Giorgio Caviglia, Trifacta Inc</li>
<li>Guoliang Li, Tsinghua University</li>
<li>Harish Doraiswamy, NYU Data Science Center</li>
<li>Iddo Drori, NYU and Columbia University</li>
<li>James Terwilliger, Microsoft Research</li>
<li>Jessica Hullman, University of Washington</li>
<li>Joseph M. Hellerstein, UC Berkeley</li>
<li>Leilani Battle, Univeristy of Maryland, College Park</li>
<li>Martin Kersten, CWI</li>
<li>Olga Papemmanouil, Brandeis University</li>
<li>Oliver Kennedy, University at Buffalo</li>
<li>Patrick Olivier, Newcastle University</li>
<li>Remco Chang, Tufts University</li>
<li>Rick Cole, Tableau Software</li>
<li>Stratos Idreos, Harvard University</li>
<li>Thibault Sellam, Columbia University</li>
<li>Tim Kraska, Brown University</li>
<li>Tiziana Catarci, Sapienza Universit di Roma</li>
<li>Yunyao Li, IBM Research</li> -->
  			 		</ul>
  			 	</p>
			 
				<h2>Steering Committee</h2>
				<p>
					<ul>
						<li>Carsten Binnig (TU Darmstadt)</li>
						<li>Juliana Friere (New York University)</li>						
						<li>Joseph M. Hellerstein (University of California, Berkeley)</li>
						<li>Aditya Parameswaran (University of Illinois)</li>
  			 </ul></p>
			 
			 
			</p>
			</div>
						
		</section>			


<style>
  li.paper {
  }
  p.session {
    margin-top: 1em;
  }
  span.time {
    width: 15ex;
    text-align: left;
  }
  span.authors {
    display: block;
    font-size: smaller;
  }
  span.title {
    display: block;
    font-weight: bold;
  }
  span.toggle {
    font-size: 10pt;
    display: block;
    cursor: pointer;
  }
  span.toggle:hover {
    text-decoration: underline;
  }
  span.abstract {
  }
</style>

<!--
 <section class='row'>
   <div class="col-full">

      <p class='session'>
        <span class='time'>8:00-8:10</span>
        <span class='sessiontitle'>Opening</span>
      </p>
<ul>

</ul>

      <p class='session'>
        <span class='time'>8:10-9:00</span>
        <span class='sessiontitle'>Keynote</span>
      </p>
<ul>

</ul>

      <p class='session'>
        <span class='time'>9:00-10:30</span>
        <span class='sessiontitle'>Session 1: Visual Interactive Exploration (Session Chair: Alan Fekete)</span>
      </p>
<ul>


      <li class='paper'>
        <span class='title'> Human-in-the-Loop Data Analysis: A Personal Perspective.</span>
        <span class='authors'>Anhai Doan (University of Wisconsin-Madison)</span>
        <span id='toggle_20' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_20").click(function() {
            $("#abstract_20").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_20">In the past few years human-in-the-loop data analysis (HILDA) has received significant growing attention. Most HILDA works have focused on concrete problems. In this paper I take a step back and discuss several ``big picture'' questions regarding HILDA.  First, I discuss problems that I believe should fall under the scope of the field, including some that have received little attention, such as fostering user communities that develop data repositories and tools. Next, I discuss important aspects in developing HILDA solutions that I believe should receive more attention. These include solving problems that real users care about, developing how-to guides to users, building end-to-end systems (such as extending the ``Pandas system''), developing benchmarks and challenges, and developing a theory of human data interaction.  Finally, I speculate about the future of the field, and discuss the dangers it can face, given that many other communities are also working on related problems. I argue that a focus on end-to-end problems and system building is important for us to thrive and make significant impacts.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> ViDeTTe Interactive Notebooks.</span>
        <span class='authors'>Costas Zarifis (University of California San Diego)</span>
        <span id='toggle_12' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_12").click(function() {
            $("#abstract_12").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_12">Interactive notebooks allow the use of popular languages, such as python, for composing data analytics projects. The interface they provide, enables data scientists to import data, analyze them and compose the results into easily readable report-like web pages, that can contain re-runnable code, visualizations and textual description of the entire process, all in one place. Scientists can then share such pages with other users in order to present their findings, collaborate and further explore the underlying data.  However, as we show in this work, interactive notebooks lack in interactivity and ease of use, both for the data scientist that composes the notebook and, even more so, for the reader of the published notebook. First, utilizing libraries that obtain, process and visualize data, requires technical expertise that often exceeds the skill-set of a typical data scientist. Second, while the user interface allows readers to rerun or extend the code included in the notebook, it does not allow them to directly interact with the generated visualizations in order to trigger additional computation and further explore the underlying data. This means that only code-literate readers can further interact with and extend such notebooks, while the rest can only passively read the provided report.  To address these issues, we propose ViDeTTe, an engine that enhances interactive notebooks with capabilities that benefit both data scientists and non-technical notebook readers. ViDeTTe uses a declarative language to simplify data retrieval and data visualization for analysts. The generated visualizations are capable of collecting the reader's input and reacting to it. Additionally, the user input is utilized by ViDeTTe's propagation algorithm, to identify subsequent parts of the notebook that depend on it and cause their reevaluation. By doing this, ViDeTTe offers enhanced data exploratory capabilities to readers, without requiring any coding skills.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Towards a Unified Representation of Insight in Human-in-the-Loop Analytics: A User Study.</span>
        <span class='authors'>Eser Kandogan (IBM) and Ulrich Engelke (CSIRO)</span>
        <span id='toggle_8' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_8").click(function() {
            $("#abstract_8").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_8">Understanding what insights people draw from data visualizations is critical for human-in-the loop analytics systems to facilitate mixed-initiative analysis. In this paper we present results from a large user study on insights extracted from commonly used charts. We report several patterns of insights we observed and analyze their semantic structure to identify key considerations towards a unified formal representation of insight, human or computer generated. We also present a model of insight generation process, where humans and computers work cooperatively, building on each other's knowledge, where a common representation acts as the currency of interaction. While not going as far as proposing a formalism, we pointed to a few potential directions for representing insight. We believe our findings could also inform the design of novel human-in-the-loop analytics systems.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Evaluating Visual Data Analysis Systems: A Discussion Report.</span>
        <span class='authors'>Leilani Battle (University of Washington), Marco Angelini (Sapienza University of Rome), Carsten Binnig (TU Darmstadt), Tiziana Catarci (Sapienza University of Rome), Philipp Eichmann (Brown University), Jean-Daniel Fekete (INRIA), Giuseppe Santucci (Sapienza University of Rome), Michael Sedlmair (Jacobs University Bremen) and Wesley Willett (University of Calgary)</span>
        <span id='toggle_10' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_10").click(function() {
            $("#abstract_10").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_10">Visual data analysis is a key tool for helping people to make sense of and interact with massive data sets. However, existing evaluation methods (e.g., database benchmarks, individual user studies) fail to capture the key points that make systems for visual data analysis (or visual data systems) challenging to design.  In November 2017, members of both the Database and Visualization communities came together in a Dagstuhl seminar to discuss the grand challenges in the intersection of data analysis and interactive visualization.  In this paper, we report on the discussions of the working group on the evaluation of visual data systems, which addressed questions centered around developing better evaluation methods, such as "How do the different communities evaluate visual data systems?" and "What we could learn from each other to develop evaluation techniques that cut across areas?".  In their discussions, the group brainstormed initial steps towards new joint evaluation methods and developed a first concrete initiative - a trace repository of various real-world workloads and visual data systems - that enables researchers to derive evaluation setups (e.g., performance benchmarks, user studies) under more realistic assumptions, and enables new evaluation perspectives (e.g., broader meta analysis across analysis contexts, reproducibility and comparability across systems).
</span>
      </li>
      

      <li class='paper'>
        <span class='title'>(Vis Abstract) Visual Exploration of Deep Learning Models in Industry.</span>
        <span class='authors'>Minsuk Kahng (Georgia Institute of Technology), Pierre Andrews (Facebook), Aditya Kalro (Facebook) and Duen Horng Chau (Georgia Institute of Technology)</span>
        <span id='toggle_23' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_23").click(function() {
            $("#abstract_23").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_23">While deep learning has led to major breakthroughs in various domains, understanding these models remains a challenge. Despite the increasing interest in developing visualization tools for deep learning interpretation, the complexity of large-scale models and datasets used in industry pose unique design challenges. It motivates us to design and develop ActiVis, a visual analytics system for deep neural network models, now deployed on Facebook's machine learning platform. With ActiVis, users can get a high-level overview of a model and drill down into its activations at both instance- and subset-level.  Our one-page abstract has been uploaded to the system. This abstract paper is a summary for the paper presented at the IEEE VIS'17 conference, titled "ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models."
</span>
      </li>
      

</ul>

      <p class='session'>
        <span class='time'>10:30-11:00</span>
        <span class='sessiontitle'>Coffee Break (Location: Houston Foyer)</span>
      </p>
<ul>

</ul>

      <p class='session'>
        <span class='time'>11:10-12:30</span>
        <span class='sessiontitle'>Session 2: Engines and Languages (Session Chair: Oliver Kennedy)</span>
      </p>
<ul>


      <li class='paper'>
        <span class='title'> DIVE: A Mixed-Initiative System Supporting Integrated Data Exploration Workflows.</span>
        <span class='authors'>Kevin Hu (Massachusetts Institute of Technology), Diana Orghian (Massachusetts Institute of Technology) and César Hidalgo (Massachusetts Institute of Technology)</span>
        <span id='toggle_6' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_6").click(function() {
            $("#abstract_6").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_6">Generating knowledge from data is an increasingly important activity. This process of data exploration consists of multiple tasks: data ingestion, visualization, statistical analysis, and storytelling. Though these tasks are complementary, analysts often execute them in separate, standalone tools. Moreover, these tools have steep learning curves due to their reliance on manual query specification. Here, we describe the design and implementation of DIVE, a web-based system that integrates state-of-the-art data exploration features into a single tool. DIVE contributes a mixed-initiative interaction scheme that combines recommendation with point-and-click manual specification, and a consistent visual language that unifies different stages of the data exploration workflow.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Querying Videos Using DNN Generated Labels by Designing DSL driven UIs.</span>
        <span class='authors'>Wu Yifan (University of California, Berkeley), Steven Drucker (Microsoft), Matthai Philipose (Microsoft) and Lenin Ravindranath (Microsoft)</span>
        <span id='toggle_3' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_3").click(function() {
            $("#abstract_3").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_3">Massive amounts of videos are generated for entertainment, security, and science, powered by a  growing supply of user-produced video hosting services.  Unfortunately, searching for videos is complicated due to the lack of content annotations.  While many have tackled this problem before, recent breakthroughs in image labeling with deep neural networks (DNNs) create a unique opportunity for re-imagining the querying of videos.  To exploit this opportunity, We introduce a new query language that operates on the output labels of DNNs trained for object recognition. By applying visualization techniques, we also create a graphical query interface that supports fast refinement of queries, which helps to overcome limitations in label consistency and accuracy.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Optimally Leveraging Density and Locality for Exploratory Browsing and Sampling.</span>
        <span class='authors'>Albert Kim (Massachusetts Institute of Technology), Liqi Xu (University of Illinois Urbana-Champaign), Tarique Siddiqui (University of Illinois Urbana-Champaign), Silu Huang (University of Illinois Urbana-Champaign), Samuel Madden (Massachusetts Institute of Technology) and Aditya Parameswaran (University of Illinois Urbana-Champaign)</span>
        <span id='toggle_18' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_18").click(function() {
            $("#abstract_18").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_18">Exploratory data analysis often involves repeatedly browsing a small sample of records that satisfy certain predicates. However, existing database systems are not optimized for such queries. We propose a fast query evaluation engine, called NeedleTail, aimed at letting analysts browse a subset of the query result on large datasets as quickly as possible, independent of the overall size of the result. NeedleTail introduces density maps, a lightweight in-memory indexing structure, and a set of efficient and theoretically sound algorithms to quickly locate promising blocks, trading of locality and density. In settings where the samples are used to compute aggregates, we extend techniques from survey sampling to mitigate the bias in our samples. Our experimental results demonstrate that NeedleTail returns results 7× faster on average and can achieve the same error rate as random sampling but in much less time.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Source Selection Languages: A Usability Evaluation.</span>
        <span class='authors'>Ixent Galpin (Universidad Jorge Tadeo Lozano), Edward Abel (The University of Manchester) and Norman Paton (The University of Manchester)</span>
        <span id='toggle_7' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_7").click(function() {
            $("#abstract_7").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_7">When looking to obtain insights from data, and given numerous possible data sources, there are certain quality criteria that retrieved data from selected sources should exhibit so as to be most fit-for-purpose. An effective source selection algorithm can only provide good results in practice if the requirements of the user have been suitably captured, and therefore, an important consideration is how users can effectively express their requirements.  In this paper, we carry out an experiment to compare user performance in two different languages for expressing user requirements in terms of data quality characteristics, pairwise comparison of criteria values, and single objective constrained optimization. We employ crowd-sourcing to evaluate, for a set of tasks, user ability to choose effective formulations in each language. The results of this initial study show that users were able to determine more effective formulations for the tasks using pairwise comparisons. However, user usability evaluations show that the languages were evaluated similarly in terms of subjective user preference.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Provenance for Interactive Visualizations.</span>
        <span class='authors'>Fotis Psallidas (Columbia University) and Eugene Wu (Columbia University)</span>
        <span id='toggle_13' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_13").click(function() {
            $("#abstract_13").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_13">We highlight the connections between data provenance and interactive visualizations.  To do so, we first incrementally add interactions to a visualization and show how these interactions are readily expressible in terms of provenance.  We then describe how an interactive visualization system that natively supports provenance can be easily extended with novel interactions.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'>(Vis Abstract) A Visual Interaction Framework for Dimensionality Reduction Based Data Exploration.</span>
        <span class='authors'>Marco Cavallo (IBM) and Cagatay Demiralp (IBM)</span>
        <span id='toggle_24' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_24").click(function() {
            $("#abstract_24").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_24">Dimensionality reduction is a common method for analyzing and visualizing high-dimensional data. However, reasoning dynamically about the results of a dimensionality reduction is difficult. Dimensionality-reduction algorithms use complex optimizations to reduce the number of dimensions of a dataset, but these new dimensions often lack a clear relation to the initial data dimensions, thus making them difficult to interpret.  Here we propose a visual interaction framework to improve dimensionality-reduction based exploratory data analysis. We introduce two interaction techniques, forward projection and backward projection, for dynamically reasoning about dimensionally reduced data. We also contribute two visualization techniques, prolines and feasibility maps, to facilitate the effective use of the proposed interactions.  We apply our framework to PCA and autoencoder-based dimensionality reductions. Through data-exploration examples, we demonstrate how our visual interactions can improve the use of dimensionality reduction in exploratory data analysis.
</span>
      </li>
      

</ul>

      <p class='session'>
        <span class='time'>12:30-14:00</span>
        <span class='sessiontitle'>Lunch (Location: Houston 123)</span>
      </p>
<ul>

</ul>

      <p class='session'>
        <span class='time'>14:00-15:30</span>
        <span class='sessiontitle'>Session 3: Data Curation & Quality (Session Chair: Carlos Scheidegger)</span>
      </p>
<ul>


      <li class='paper'>
        <span class='title'>Beaver: Towards a Declarative Schema Mapping.</span>
        <span class='authors'>Zhongjun Jin (University of Michigan), Christopher Baik (University of Michigan), Michael Cafarella (University of Michigan) and H V. Jagadish (University of Michigan). </span>
        <span id='toggle_1' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_1").click(function() {
            $("#abstract_1").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_1">Schema mapping describes how to transform data of the source schemas into the data of the target schema. Manually writing com- plete schema mapping speci cations requires a deep understanding of the source and target schema which can be burdensome for the user. Programming By Example (PBE) schema mapping systems have attempted to reduce this burden by allowing the user to declar- atively specify the schema mapping using a few sample records. However, specifying real records can sometimes be di cult for the user too, whereas the user might have other useful insights about the desired schema mapping. In this paper, we develop a new schema mapping technique, Beaver, that enables an interaction model that gives the user far more  exibility in describing the de- sired schema mapping. The end user is not limited to providing target schema examples but may also provide other types of de- scriptions, such as the data type or value range of target schema columns. Moreover, beyond constraining the target schema itself, the user can provide constraints for the schema mapping process. We propose a search algorithm with on-line pruning that e ciently solves the schema mapping problem. We implemented a prototype of our schema mapping technique and experimentally evaluated the e ciency of the system in handling traditional PBE schema map- ping test cases, as well as our newly-proposed declarative schema mapping test cases. The experiment results suggest that the end user can provide declarative queries which we believe are easier to input and retain a reasonable system e ciency as they have for traditional PBE queries.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> SchemaDrill: Interactive Semi-Structured Schema Design.</span>
        <span class='authors'>William Spoth (University at Buffalo), Ting Xie (University at Buffalo), Oliver Kennedy (University at Buffalo), Dieter Gawlick (Oracle), Ying Yang (Oracle), Zhen Hua-Liu (Oracle) and Beda Hammerschmidt (Oracle)</span>
        <span id='toggle_17' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_17").click(function() {
            $("#abstract_17").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_17">Ad-hoc data models like Json make it easy to evolve schemas and to multiplex different data-types into a single stream.  This flexibility makes Json great for generating data, but also makes it much harder to query, ingest into a database, and index.  In this paper, we explore the first step of Json data loading: schema design.  Specifically, we consider the challenge of designing schemas for existing Json datasets as an interactive problem.  We present SchemaDrill, a roll-up/drill-down style interface for exploring collections of Json records.  SchemaDrill helps users to visualize the collection, identify relevant fragments, and map it down into one or more flat, relational schemas.  We describe and evaluate two key components of SchemaDrill: (1) A summary schema representation that significantly reduces the complexity of Json schemas without a meaningful reduction in information content, and (2) A collection of schema visualizations that help users to qualitatively survey variability amongst different schemas in the collection.  
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> What Type of a Matcher Are You? - Human and Algorithmic Matchers Coordination.</span>
        <span class='authors'>Roee Shraga (Technion - Israel Institute of Technology), Avigdor Gal (Technion - Israel Institute of Technology) and Haggai Roitman (IBM Research - AI)</span>
        <span id='toggle_2' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_2").click(function() {
            $("#abstract_2").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_2">In this work we explore relationships between human and algorithmic schema matchers. We provide a novel approach to similar schema matchers termed \emph{coordinated matchers} and use it to predict future human matching choices. We show throughout a comprehensive analysis that human matchers are usually coordinated with intuitive algorithms, \emph{e.g.,} based on attribute name similarity, and frequently do not assign lower confidence levels, which indicates over confidence in their choices. Finally, we show that human choices can be reasonably predicted using collaborative algorithmic opinions based on matchers coordination.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> Draining the Data Swamp: A Similarity-based Approach.</span>
        <span class='authors'>Will Brackenbury (University of Chicago), Rui Liu (University of Chicago), Mainack Mondal (University of Chicago), Aaron Elmore (University of Chicago), Blase Ur (University of Chicago), Kyle Chard (University of Chicago) and Michael Franklin (University of Chicago)</span>
        <span id='toggle_16' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_16").click(function() {
            $("#abstract_16").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_16">While hierarchical namespaces such as filesystems and repositories have long been used to organize data, the rapid increase in data production places increasing strain on users who wish to make use of the data. So called “data lakes” embrace the storage of data in its natural form, integrating and organizing in a Pay-as-you-go fashion. While this model defers the upfront cost of integration, the result is that data is unusable for discovery or analysis until it is processed. Thus, data scientists are forced to spend significant time and energy on mundane tasks such as data discovery, cleaning, integration, and management – when this is neglected, “data lakes” become “data swamps.” Prior work suggests that pure computational methods for resolving issues with the data discovery and management components are insufficient. Here, we provide evidence to confirm this hypothesis, showing that methods such as automated file clustering are unable to extract the necessary features from repositories to provide useful information to end-user data scientists, or make effective data management decisions on their behalf. We argue that the combination of frameworks for specifying file similarity and human-in-the-loop interaction is needed to aid automated organization. We propose an initial step here, classifying several dimensions by which items may be considered similar: the data, its origin, and its current characteristics.  We initially consider this model in the context of identifying data that can be integrated or managed collectively. We additionally explore how current methods can be used to automate decision making using real-world data repository and file systems, and suggest how an online user study could be developed to further validate this hypothesis.
</span>
      </li>
      

      <li class='paper'>
        <span class='title'> (Vis Abstract) Interactive Visual Analytics for Simpson’s Paradox Detection.</span>
        <span class='authors'>Chenguang Xu (University of oklahoma), Sarah Brown (University of California, Berkeley), Christan Grant (University of oklahoma) and Chris Weaver (University of Oklahoma)</span>
        <span id='toggle_21' class='toggle'>(toggle abstract)</span>
        <script>
        $(function() {
          $("#toggle_21").click(function() {
            $("#abstract_21").toggle()
          });
        })
        </script>
      

        <span style='display:none' class='abstract' id="abstract_21">When a trend is observed in aggregate data, Simpson’s paradox is the phenomenon that some or all of the partitions of a data set exhibit the opposite trend. Detecting Simpson’s paradox uncovers the anomaly in a data set, and helps us to make prudent data-driven decisions after looking deeper into the data. The analysis of Simpson’s paradox often requires the comparison of the trends between the whole population and the subpopulations. This comparison is typically the most complicated step of the analysis process, especially for data with high dimensions. We use the bivariate color scheme to accurately illustrate the relationship between the trend of the association in the whole population and within the subpopulations. We provide a novel visual analytics approach to facilitate the exploration of the data to detect Simpson’s paradox. The detection and analysis are tightly coupled by multiple coordinated views. Our multiple views provide users with not only an overview of the entire data set but also details when needed. The interactive features empowered user to do analyses effectively and efficiently. We will demonstrate that using our application, users are able to detect Simpson’s paradox and draw insights from data sets with confidence.
</span>
      </li>
      


</ul>

      <p class='session'>
        <span class='time'>15:30-16:30</span>
        <span class='sessiontitle'>Poster Session (Location: Houston 56) </span>
      </p>
<ul>

</ul>

      <p class='session'>
        <span class='time'>16:30-17:30</span>
        <span class='sessiontitle'>Panel (Moderator: Eugene Wu)</span>
      </p>
<ul>

</ul>

      <p class='session'>
        <span class='time'>17:30-18:00</span>
        <span class='sessiontitle'>Closing Remarks</span>
      </p>
<ul>


    </div>
  </section>
 -->

	<section class="row">
			<div class="col-full">
				<h2>Sponsors</h2>
				<p><a href="http://www.google.com"><img class="sponsor" src="img/google.png" alt="Google" width="300px"/></a></p>
			</div>

	</section>
	
	
  	<section class="row">
			
			<div class="col">
				<h2>Contact</h2>
				<p>
					For questions, email us at <a href="mailto:workshop@hilda.io">workshop@hilda.io</a>.
				</p>
			</div>
			<div class="col">
				<h2>Follow us</h2>
				<p>
					Join us on <a href="http://twitter.com/hildaworkshop">Twitter</a>.
				</p>
			</div>
		</section>

 
	</div>

	<script src="js/vendor/jquery.fluidbox.min.js"></script>
	<script src="js/main.js"></script>

	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-67595208-1', 'auto');
	  ga('send', 'pageview');

	</script>

</body>
</html>

<!-- © 2014 - Based on free website template by <a href="http://www.pixelsbyrick.com">Rick Waalders</a> -->
